{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Reference:\n",
        "https://github.com/rohan-paul/MachineLearning-DeepLearning-Code-for-my-YouTube-Channel/blob/master/NLP/YT_Fine_tuning_BERT_NER_v1.ipynb"
      ],
      "metadata": {
        "id": "P_X8VqnRTUyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUf_kEPsABez",
        "outputId": "aff5a6b6-da61-437c-d782-2496a66a55c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_iVrOprz3NK"
      },
      "outputs": [],
      "source": [
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, filenames_list):\n",
        "        self.sentences = []\n",
        "        self.words = set()\n",
        "        self.tags = set()\n",
        "        for filename in filenames_list:\n",
        "          with open(filename) as f:\n",
        "              sentence = []\n",
        "              for line in f:\n",
        "                  line = line.strip()\n",
        "                  if (len(line) == 0 or line.startswith(\"-DOCSTART-\") or line.startswith(\"......\")):\n",
        "                      if len(sentence) != 0:\n",
        "                        self.sentences.append(sentence)\n",
        "                        sentence = []\n",
        "                      continue\n",
        "                  else:\n",
        "                      ls = line.split(' ')\n",
        "                      word, tag = ls[0],ls[3]\n",
        "                      self.words.add(word)\n",
        "                      self.tags.add(tag)\n",
        "                      sentence.append((word,tag))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzhA2Tnm1QTo"
      },
      "outputs": [],
      "source": [
        "#MCHP_dataset_1\n",
        "files = ['/content/drive/MyDrive/MasterThesis/NER/MCHP/dataset_1/cn569258-pin.conll', '/content/drive/MyDrive/MasterThesis/NER/MCHP/dataset_2/project-13-at-2022-06-14-08-59-1d16c7ec.conll']\n",
        "getter = SentenceGetter(files)\n",
        "sentences = getter.sentences\n",
        "words = getter.words\n",
        "tags = list(getter.tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtgmmNlLjyde",
        "outputId": "b4986b4e-a80a-44a7-d641-40dbcd253ef5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I-Pin', 'O', 'B-Pin']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5mymqkx2faS"
      },
      "outputs": [],
      "source": [
        "from future.utils import iteritems\n",
        "\n",
        "tag2idx = {t: i for i, t in enumerate(tags)}\n",
        "\n",
        "idx2tag = {v: k for k, v in iteritems(tag2idx)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M19E4Nu3U0r",
        "outputId": "86397fef-80bc-4380-d5a4-d5aa76bc8403"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('Appendix', 'O'),\n",
              "  ('D:', 'O'),\n",
              "  ('List', 'O'),\n",
              "  ('of', 'O'),\n",
              "  ('Tables', 'O'),\n",
              "  ('Table', 'O'),\n",
              "  ('2-1:', 'O'),\n",
              "  ('Pinout', 'O'),\n",
              "  ('List', 'O')],\n",
              " [('Table', 'O'),\n",
              "  ('3-1:', 'O'),\n",
              "  ('Power', 'O'),\n",
              "  ('Down', 'O'),\n",
              "  ('Scenarios', 'O')]]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "sentences[0:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gzz_3tm_2sZ3",
        "outputId": "5b20cfa4-da82-4460-b737-bd6ee8b604cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'I-Pin': 0, 'O': 1, 'B-Pin': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "tag2idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdVFyVUC2xPn"
      },
      "outputs": [],
      "source": [
        "#sentance tag seperator\n",
        "def sentence_tag_seperator(sentence_list, tags_dict):\n",
        "  tokens = []\n",
        "  tags = []\n",
        "  for sentence in sentence_list:\n",
        "    inner_sentence_words = []\n",
        "    inner_sentence_tags = []\n",
        "    for word in sentence:\n",
        "      inner_sentence_words.append(word[0])\n",
        "      inner_sentence_tags.append(tag2idx[word[1]])\n",
        "    tokens.append(inner_sentence_words)\n",
        "    tags.append(inner_sentence_tags)\n",
        "\n",
        "  return {\"tokens\" : tokens,\n",
        "          \"tags\" : tags}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_data = sentence_tag_seperator(sentences,tag2idx)"
      ],
      "metadata": {
        "id": "LsecOkaHrJZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-HWwLQGrQ1x",
        "outputId": "0d014471-b219-4707-d7e6-3e234293279c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['tokens', 'tags'])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 70,20,10 data split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_data, X_test, Y_data, y_test = train_test_split(total_data['tokens'],total_data['tags'],test_size=0.20,shuffle=True, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_data,Y_data,test_size=0.10,shuffle=True, random_state=42)\n",
        "\n",
        "train_data = {\"tokens\" : X_train,\"tags\" : y_train}\n",
        "valid_data = {\"tokens\" : X_val,\"tags\" : y_val}\n",
        "test_data = {\"tokens\" : X_test,\"tags\" : y_test}\n",
        "\n",
        "\n",
        "print(\n",
        "        '\\X_tokens length:', len(total_data['tokens']),\n",
        "        '\\ntrain_tokens length:', len(X_train),\n",
        "        '\\nval_tokens length:', len(X_val),\n",
        "        '\\ntest_tokens length:', len(X_test),\n",
        "        '\\n\\nY_tags length:', len(total_data['tags']),\n",
        "        '\\ntrain_tags:', len(y_train),\n",
        "        '\\nval_tags:', len(y_val),\n",
        "        '\\ntest_tags:', len(y_test)\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM_1mAdulKFR",
        "outputId": "c39f5896-dae0-4784-ca36-49a6b2ed99f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\X_tokens length: 545 \n",
            "train_tokens length: 392 \n",
            "val_tokens length: 44 \n",
            "test_tokens length: 109 \n",
            "\n",
            "Y_tags length: 545 \n",
            "train_tags: 392 \n",
            "val_tags: 44 \n",
            "test_tags: 109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDER8hXnuA_d",
        "outputId": "1c06d448-7f6e-4c94-f625-565ac16d319d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['tokens', 'tags'])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "test_data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvzkN_JD6Hqm"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets tokenizers seqeval -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-N0bLEd56gai"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import datasets \n",
        "from transformers import BertTokenizerFast\n",
        "from transformers import AutoModelForTokenClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers.data.data_collator import DataCollatorForTokenClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98IEPOM77EYE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ee42122-ae0a-474f-e2d4-b7779c4dc897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at /content/drive/MyDrive/MasterThesis/Bert/conll_ner_model and are newly initialized because the shapes did not match:\n",
            "- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([3, 768]) in the model instantiated\n",
            "- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Transfer Learning Approach\n",
        "# tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
        "model_fine_tuned = AutoModelForTokenClassification.from_pretrained(\"/content/drive/MyDrive/MasterThesis/Bert/conll_ner_model\", num_labels = 3, ignore_mismatched_sizes=True)\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"/content/drive/MyDrive/MasterThesis/Bert/conll_ner_tokenizer\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_fine_tuned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXb-1jvqGFXX",
        "outputId": "6f3ba3f9-4ff5-42ab-ad8d-a08083c037e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertForTokenClassification(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTtqak7Q9T7O"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(example_data, label_all_tokens = True):\n",
        "  tokenized_inputs = tokenizer(example_data['tokens'], is_split_into_words=True, truncation=True)\n",
        "  labels = []\n",
        "\n",
        "  for i, lable in enumerate(example_data['tags']):\n",
        "    word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "\n",
        "    previous_word_idx = None\n",
        "\n",
        "    label_ids = []\n",
        "\n",
        "    for word_idx in word_ids:\n",
        "      if word_idx is None:\n",
        "        label_ids.append(-100)\n",
        "      elif word_idx != previous_word_idx:\n",
        "        label_ids.append(lable[word_idx])\n",
        "      else:\n",
        "        label_ids.append(lable[word_idx] if label_all_tokens else -100)\n",
        "      \n",
        "      previous_word_idx = word_idx\n",
        "    labels.append(label_ids)\n",
        "  tokenized_inputs[\"labels\"] = labels\n",
        "  tokenized_inputs[\"tokens\"] = example_data['tokens']\n",
        "  tokenized_inputs[\"tags\"] = example_data['tags']\n",
        "  return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byBEN6ikjW1g"
      },
      "outputs": [],
      "source": [
        "#Final tokenized train data\n",
        "tokenized_dataset_train = tokenize_and_align_labels(train_data)\n",
        "#convert to apache arrow Datasets to train the model\n",
        "tokenized_dataset_train = datasets.Dataset.from_dict(tokenized_dataset_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMitG45DktDc"
      },
      "outputs": [],
      "source": [
        "#Final tokenized valid data\n",
        "tokenized_dataset_valid = tokenize_and_align_labels(valid_data)\n",
        "tokenized_dataset_valid = datasets.Dataset.from_dict(tokenized_dataset_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttrkEayAkssq"
      },
      "outputs": [],
      "source": [
        "#Final tokenized test data\n",
        "tokenized_dataset_test = tokenize_and_align_labels(test_data)\n",
        "tokenized_dataset_test = datasets.Dataset.from_dict(tokenized_dataset_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l4bXiwZv5Rj",
        "outputId": "5ce293df-76b1-496f-a166-b3a457904fb1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels', 'tokens', 'tags'],\n",
              "    num_rows: 109\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "tokenized_dataset_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyBEusTboJtx"
      },
      "outputs": [],
      "source": [
        "args = TrainingArguments(\n",
        "    '/content/drive/MyDrive/MasterThesis/Bert/PIN/test-ner',\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    do_train = True,\n",
        "    do_predict=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZnhfWBDDJtw",
        "outputId": "e6295104-eb54-4f30-dabd-bf03f1157e4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainingArguments(\n",
              "_n_gpu=1,\n",
              "adafactor=False,\n",
              "adam_beta1=0.9,\n",
              "adam_beta2=0.999,\n",
              "adam_epsilon=1e-08,\n",
              "auto_find_batch_size=False,\n",
              "bf16=False,\n",
              "bf16_full_eval=False,\n",
              "data_seed=None,\n",
              "dataloader_drop_last=False,\n",
              "dataloader_num_workers=0,\n",
              "dataloader_pin_memory=True,\n",
              "ddp_bucket_cap_mb=None,\n",
              "ddp_find_unused_parameters=None,\n",
              "ddp_timeout=1800,\n",
              "debug=[],\n",
              "deepspeed=None,\n",
              "disable_tqdm=False,\n",
              "do_eval=True,\n",
              "do_predict=True,\n",
              "do_train=True,\n",
              "eval_accumulation_steps=None,\n",
              "eval_delay=0,\n",
              "eval_steps=None,\n",
              "evaluation_strategy=epoch,\n",
              "fp16=False,\n",
              "fp16_backend=auto,\n",
              "fp16_full_eval=False,\n",
              "fp16_opt_level=O1,\n",
              "fsdp=[],\n",
              "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
              "fsdp_min_num_params=0,\n",
              "fsdp_transformer_layer_cls_to_wrap=None,\n",
              "full_determinism=False,\n",
              "gradient_accumulation_steps=1,\n",
              "gradient_checkpointing=False,\n",
              "greater_is_better=None,\n",
              "group_by_length=False,\n",
              "half_precision_backend=auto,\n",
              "hub_model_id=None,\n",
              "hub_private_repo=False,\n",
              "hub_strategy=every_save,\n",
              "hub_token=<HUB_TOKEN>,\n",
              "ignore_data_skip=False,\n",
              "include_inputs_for_metrics=False,\n",
              "jit_mode_eval=False,\n",
              "label_names=None,\n",
              "label_smoothing_factor=0.0,\n",
              "learning_rate=2e-05,\n",
              "length_column_name=length,\n",
              "load_best_model_at_end=False,\n",
              "local_rank=-1,\n",
              "log_level=passive,\n",
              "log_level_replica=warning,\n",
              "log_on_each_node=True,\n",
              "logging_dir=/content/drive/MyDrive/Shreya/MasterThesis/Bert/PIN/test-ner/runs/May03_20-03-45_99e920aa8140,\n",
              "logging_first_step=False,\n",
              "logging_nan_inf_filter=True,\n",
              "logging_steps=500,\n",
              "logging_strategy=steps,\n",
              "lr_scheduler_type=linear,\n",
              "max_grad_norm=1.0,\n",
              "max_steps=-1,\n",
              "metric_for_best_model=None,\n",
              "mp_parameters=,\n",
              "no_cuda=False,\n",
              "num_train_epochs=3,\n",
              "optim=adamw_hf,\n",
              "optim_args=None,\n",
              "output_dir=/content/drive/MyDrive/Shreya/MasterThesis/Bert/PIN/test-ner,\n",
              "overwrite_output_dir=False,\n",
              "past_index=-1,\n",
              "per_device_eval_batch_size=16,\n",
              "per_device_train_batch_size=16,\n",
              "prediction_loss_only=False,\n",
              "push_to_hub=False,\n",
              "push_to_hub_model_id=None,\n",
              "push_to_hub_organization=None,\n",
              "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
              "ray_scope=last,\n",
              "remove_unused_columns=True,\n",
              "report_to=['tensorboard'],\n",
              "resume_from_checkpoint=None,\n",
              "run_name=/content/drive/MyDrive/Shreya/MasterThesis/Bert/PIN/test-ner,\n",
              "save_on_each_node=False,\n",
              "save_safetensors=False,\n",
              "save_steps=500,\n",
              "save_strategy=steps,\n",
              "save_total_limit=None,\n",
              "seed=42,\n",
              "sharded_ddp=[],\n",
              "skip_memory_metrics=True,\n",
              "tf32=None,\n",
              "torch_compile=False,\n",
              "torch_compile_backend=None,\n",
              "torch_compile_mode=None,\n",
              "torchdynamo=None,\n",
              "tpu_metrics_debug=False,\n",
              "tpu_num_cores=None,\n",
              "use_ipex=False,\n",
              "use_legacy_prediction_loop=False,\n",
              "use_mps_device=False,\n",
              "warmup_ratio=0.0,\n",
              "warmup_steps=0,\n",
              "weight_decay=0.01,\n",
              "xpu_backend=None,\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88deTazorEzr"
      },
      "outputs": [],
      "source": [
        "from transformers.data.data_collator import DataCollatorForTokenClassification\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bqyusla5reMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e4abd7f-aee4-46c6-a843-1b85e37fbbf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-80ed98bfe56d>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = datasets.load_metric(\"seqeval\")\n"
          ]
        }
      ],
      "source": [
        "metric = datasets.load_metric(\"seqeval\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wg5sgGGOOuW9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6VHIRP1OuT-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPxk6nemjhYF"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_preds): \n",
        "    pred_logits, labels = eval_preds \n",
        "    \n",
        "    pred_logits = np.argmax(pred_logits, axis=2) \n",
        "    # the logits and the probabilities are in the same order,\n",
        "    # so we donâ€™t need to apply the softmax\n",
        "    \n",
        "    # We remove all the values where the label is -100\n",
        "    predictions = [ \n",
        "        [tags[eval_preds] for (eval_preds, l) in zip(prediction, label) if l != -100] \n",
        "        for prediction, label in zip(pred_logits, labels) \n",
        "    ] \n",
        "    \n",
        "    true_labels = [ \n",
        "      [tags[l] for (eval_preds, l) in zip(prediction, label) if l != -100] \n",
        "       for prediction, label in zip(pred_logits, labels) \n",
        "   ] \n",
        "    results = metric.compute(predictions=predictions, references=true_labels) \n",
        "    return { \n",
        "   \"precision\": results[\"overall_precision\"], \n",
        "   \"recall\": results[\"overall_recall\"], \n",
        "   \"f1\": results[\"overall_f1\"], \n",
        "  \"accuracy\": results[\"overall_accuracy\"], \n",
        "  } "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXyuXARzjhbO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UL9o9k2XjheI"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer( \n",
        "  model_fine_tuned, \n",
        "  args, \n",
        "  train_dataset=tokenized_dataset_train, \n",
        "  eval_dataset=tokenized_dataset_valid, \n",
        "  data_collator=data_collator, \n",
        "  tokenizer=tokenizer, \n",
        "  compute_metrics=compute_metrics \n",
        ") "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train() #Epoch 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "pKK-RVy0FHWg",
        "outputId": "8e11cab6-fe54-4d56-b1db-3369c862b3db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [75/75 01:49, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.071830</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.021818</td>\n",
              "      <td>0.042403</td>\n",
              "      <td>0.977367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.063646</td>\n",
              "      <td>0.462830</td>\n",
              "      <td>0.701818</td>\n",
              "      <td>0.557803</td>\n",
              "      <td>0.974475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.054148</td>\n",
              "      <td>0.566563</td>\n",
              "      <td>0.665455</td>\n",
              "      <td>0.612040</td>\n",
              "      <td>0.980588</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=75, training_loss=0.09500116348266602, metrics={'train_runtime': 111.1917, 'train_samples_per_second': 10.576, 'train_steps_per_second': 0.675, 'total_flos': 289911372645888.0, 'train_loss': 0.09500116348266602, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, label_ids, metrics  = trainer.predict(test_dataset = tokenized_dataset_test) #epoch 3\n",
        "metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "_HkEwdhIOVSi",
        "outputId": "ced380bd-9651-4d01-d0cf-ef560630e260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_loss': 0.03675864264369011,\n",
              " 'test_precision': 0.6127659574468085,\n",
              " 'test_recall': 0.8212927756653993,\n",
              " 'test_f1': 0.701868399675061,\n",
              " 'test_accuracy': 0.986251592118079,\n",
              " 'test_runtime': 4.844,\n",
              " 'test_samples_per_second': 22.502,\n",
              " 'test_steps_per_second': 1.445}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = np.random.randint(0,tokenized_dataset_test.shape[0]) # choose a random number between 0 and len(X_te)\n",
        "p, l, m = trainer.predict([tokenized_dataset_test[i]])\n",
        "p = np.argmax(p, axis=-1)\n",
        "\n",
        "# true = np.argmax(tokenized_dataset_test[i]['tags'], -1)\n",
        "true = tokenized_dataset_test[i]['tags']\n",
        "\n",
        "print(\"Sample number {} of {} (Test Set)\".format(i, tokenized_dataset_test.shape[0]))\n",
        "# Visualization\n",
        "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
        "print(30 * \"=\")\n",
        "\n",
        "for w, t, pred in zip(tokenized_dataset_test[i]['tokens'], true, p[0][1:(len(p[0])-1)]):\n",
        "    if w != 0:\n",
        "        print(\"{:15}: {:5} {}\".format(w, idx2tag[t], idx2tag[pred]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EmISLpJ95BfI",
        "outputId": "b3cbfb24-dcbd-452e-98ad-1d660f69983a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 16\n",
            "The following columns in the test set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample number 102 of 109 (Test Set)\n",
            "Word           ||True ||Pred\n",
            "==============================\n",
            "The            : O     O\n",
            "EHC            : O     O\n",
            "should         : O     O\n",
            "be             : O     O\n",
            "able           : O     O\n",
            "to             : O     O\n",
            "recognize      : O     O\n",
            "this           : O     O\n",
            "condition      : O     O\n",
            "since          : O     O\n",
            "the            : O     O\n",
            "RXD            : B-Pin O\n",
            "pin            : O     O\n",
            "will           : O     O\n",
            "be             : O     O\n",
            "con-           : O     O\n",
            "stantly        : O     O\n",
            "high           : O     O\n",
            "while          : O     O\n",
            "the            : O     O\n",
            "TXD            : B-Pin O\n",
            "pin            : O     O\n",
            "is             : O     O\n",
            "sending        : O     O\n",
            "out            : O     O\n",
            "data           : O     O\n",
            "(during        : O     O\n",
            "normal         : O     O\n",
            "operation      : O     O\n",
            "RXD            : B-Pin O\n",
            "should         : O     O\n",
            "at             : O     O\n",
            "least          : O     O\n",
            "track          : O     O\n",
            "all            : O     O\n",
            "TXD            : B-Pin O\n",
            "low            : O     O\n",
            "levels).       : O     O\n",
            "However,       : O     O\n",
            "if             : O     O\n",
            "the            : O     O\n",
            "EHC            : O     O\n",
            "fails          : O     O\n",
            "to             : O     O\n",
            "recognize      : O     O\n",
            "this           : O     O\n",
            "condition,     : O     O\n",
            "then           : O     O\n",
            "the            : O     O\n",
            "LIN            : B-Pin O\n",
            "driver         : O     O\n",
            "current-limiting: O     O\n",
            "protection     : O     O\n",
            "structures     : O     O\n",
            "could          : O     O\n",
            "excessively    : O     O\n",
            "heat           : O     O\n",
            "up             : O     O\n",
            "the            : O     O\n",
            "MPM85000       : O     O\n",
            "over           : O     O\n",
            "time.          : O     O\n",
            "As             : O     O\n",
            "an             : O     O\n",
            "added          : O     O\n",
            "fail-safe      : O     O\n",
            "feature,       : O     O\n",
            "the            : O     O\n",
            "MPM85000       : O     O\n",
            "includes       : O     O\n",
            "thermal        : O     O\n",
            "shutdown       : O     O\n",
            "protection,    : O     O\n",
            "wherein        : O     O\n",
            "if             : O     O\n",
            "the            : O     O\n",
            "internal       : O     O\n",
            "temperature    : O     O\n",
            "reaches        : O     O\n",
            "Tshutdown,     : O     O\n",
            "then           : O     O\n",
            "the            : O     O\n",
            "LIN            : B-Pin O\n",
            "driver         : O     O\n",
            "is             : O     O\n",
            "disabled       : O     O\n",
            "to             : O     O\n",
            "prevent        : O     O\n",
            "excessive      : O     O\n",
            "power          : O     O\n",
            "dissipation,   : O     O\n",
            "and            : O     O\n",
            "the            : O     O\n",
            "LC.TEMPERR     : O     O\n",
            "bit            : O     O\n",
            "is             : O     O\n",
            "set.           : O     O\n",
            "The            : O     O\n",
            "LIN            : B-Pin O\n",
            "driver         : O     O\n",
            "remains        : O     O\n",
            "disabled       : O     O\n",
            "until          : O     O\n",
            "the            : O     O\n",
            "internal       : O     O\n",
            "temperature    : O     O\n",
            "drops          : O     O\n",
            "below          : O     O\n",
            "Trecover       : O     O\n",
            "at             : O     O\n",
            "which          : O     O\n",
            "point          : O     O\n",
            "the            : O     O\n",
            "LIN            : B-Pin O\n",
            "driver         : O     O\n",
            "is             : O     O\n",
            "automatically  : O     O\n",
            "enabled        : O     O\n",
            "again          : O     O\n",
            "(and           : O     O\n",
            "the            : O     O\n",
            "LC.TEMPERR     : O     O\n",
            "bit            : O     O\n",
            "is             : O     O\n",
            "cleared).      : O     O\n",
            "The            : O     O\n",
            "MPM85000       : O     O\n",
            "has            : O     O\n",
            "an             : O     O\n",
            "integrated,    : O     O\n",
            "precision      : O     O\n",
            "reset          : B-Pin O\n",
            "generator      : O     O\n",
            "that           : O     O\n",
            "can            : O     O\n",
            "be             : O     O\n",
            "used           : O     O\n",
            "as             : O     O\n",
            "an             : O     O\n",
            "ECU-wide       : O     O\n",
            "power-on       : O     O\n",
            "reset          : B-Pin O\n",
            "(POR)          : O     O\n",
            "signal.        : O     O\n",
            "This           : O     O\n",
            "reset          : B-Pin O\n",
            "generator      : O     O\n",
            "monitors       : O     O\n",
            "the            : O     O\n",
            "VDDP           : B-Pin O\n",
            "pin            : O     O\n",
            "input          : O     O\n",
            "voltage,       : O     O\n",
            "which          : O     O\n",
            "should         : O     O\n",
            "be             : O     O\n",
            "connected      : O     O\n",
            "to             : O     O\n",
            "the            : O     O\n",
            "switched       : O     O\n",
            "power          : O     O\n",
            "supply         : O     O\n",
            "of             : O     O\n",
            "the            : O     O\n",
            "MOST           : O     O\n",
            "INIC           : O     O\n",
            "and/or         : O     O\n",
            "the            : O     O\n",
            "EHC.           : O     O\n",
            "Any            : O     O\n",
            "subsequent     : O     O\n",
            "voltage        : O     O\n",
            "drops          : O     O\n",
            "of             : O     O\n",
            "the            : O     O\n",
            "VDDP           : B-Pin O\n",
            "supply         : O     O\n",
            "below          : O     O\n",
            "the            : O     O\n",
            "falling        : O     O\n",
            "trip           : O     O\n",
            "point          : O     O\n",
            "(Vest          : O     O\n",
            "Fa__)          : O     O\n",
            "cause          : O     O\n",
            "the            : O     O\n",
            "MPM85000       : O     O\n",
            "to             : O     O\n",
            "assert         : O     O\n",
            "the            : O     O\n",
            "RESET          : B-Pin O\n",
            "pin            : O     O\n",
            "low            : O     O\n",
            "because        : O     O\n",
            "the            : O     O\n",
            "VDDP           : B-Pin O\n",
            "supply         : O     O\n",
            "is             : O     O\n",
            "in             : O     O\n",
            "an             : O     O\n",
            "improper       : O     O\n",
            "range          : O     O\n",
            "(also          : O     O\n",
            "referred       : O     O\n",
            "to             : O     O\n",
            "as             : O     O\n",
            "a              : O     O\n",
            "VDDP           : B-Pin O\n",
            "invalid        : O     O\n",
            "condition).    : O     O\n",
            "At             : O     O\n",
            "any            : O     O\n",
            "time,          : O     O\n",
            "the            : O     O\n",
            "current        : O     O\n",
            "state          : O     O\n",
            "of             : O     O\n",
            "the            : O     O\n",
            "RESET          : B-Pin O\n",
            "pin            : O     O\n",
            "is             : O     O\n",
            "available      : O     O\n",
            "through        : O     O\n",
            "the            : O     O\n",
            "Control        : O     O\n",
            "Port           : O     O\n",
            "by             : O     O\n",
            "reading        : O     O\n",
            "the            : O     O\n",
            "value          : O     O\n",
            "of             : O     O\n",
            "LSR.RESET      : O     O\n",
            "bit            : O     O\n",
            "in             : O     O\n",
            "the            : O     O\n",
            "Line           : O     O\n",
            "Status         : B-Pin O\n",
            "Register       : O     O\n",
            "(LSR)          : O     O\n",
            "(see           : O     O\n",
            "Section        : O     O\n",
            "10.2.3).       : O     O\n",
            "The            : O     O\n",
            "delay          : O     O\n",
            "until          : O     O\n",
            "RESET          : B-Pin O\n",
            "rises          : O     O\n",
            "differs        : O     O\n",
            "depending      : O     O\n",
            "on             : O     O\n",
            "how            : O     O\n",
            "the            : O     O\n",
            "MPM85000       : O     O\n",
            "woke           : O     O\n",
            "up             : O     O\n",
            "from           : O     O\n",
            "Sleep          : O     O\n",
            "Mode.          : O     O\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}